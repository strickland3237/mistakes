---
layout: posts
title: Python解码视频或流测试对比
date: 2024-12-30 18:15:13 +0800
excerpt: 测试了opencv、PyNvVideoCodec、VALI、ffio、PyAV、deffcode几个python库，效果比较好是PyNvVideoCodec和VALI
---

解码流和视频测试速度，完整文件在最后[decode.py](#decode.py)  测试文件[test_decode.py](#test_decode.py) 

跳转到 [测试结果](#测试结果) 

注:  Ctrl+Shift+V 可以无格式化粘贴

# 1. [opencv-python](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)

```python
def read_frames(video_name):
    cap = cv2.VideoCapture(video_name)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print("width=", width)
    print("height=", height)
    # warmup
    for i in range(10):
        cap.read()

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        while True:
            start_per = time.perf_counter()
            num_decoded_frames += 1

            ret, frame = cap.read()
            if ret:
                yield frame
                # print(f'CV解码一帧时间：{time.perf_counter() - start_per}')
            else:
                break

    finally:
        final_elapsed = time.perf_counter() - start
        print(f"Opencv average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
```
# 2. [PyNvVideoCodec](https://docs.nvidia.com/video-technologies/pynvvideocodec/read-me/index.html)

```python
def cast_address_to_1d_bytearray(base_address, size):
    return np.ctypeslib.as_array(C.cast(base_address, C.POINTER(C.c_uint8)),
                                 shape=(size,))

def read_frames2(video_name, gpu_id=0, use_device_memory=False):
    nv_dmx = nvc.CreateDemuxer(filename=video_name)
    nv_dec = nvc.CreateDecoder(gpuid=gpu_id,
                               codec=nv_dmx.GetNvCodecId(),
                               cudacontext=0,
                               cudastream=0,
                               usedevicememory=use_device_memory)

    raw_frame = None

    seq_triggered = False
    # printing out FPS and pixel format of the stream for convenience
    print("FPS = ", nv_dmx.FrameRate())

    width = 0
    height = 0

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        # demuxer can be iterated, fetch the packet from demuxer
        for packet in nv_dmx:
            # Decode returns a list of packets, range of this list is from [0, size of (decode picture buffer)]
            # size of (decode picture buffer) depends on GPU, fur Turing series its 8
            for decoded_frame in nv_dec.Decode(packet):
                # 'decoded_frame' contains list of views implementing cuda array interface
                # for nv12, it would contain 2 views for each plane and two planes would be contiguous

                start_per = time.time()
                num_decoded_frames += 1

                if not seq_triggered:
                    decoded_frame_size = nv_dec.GetFrameSize()
                    print(f"decoded_frame_size={decoded_frame_size}")
                    width = nv_dec.GetWidth()
                    height = nv_dec.GetHeight()
                    print("width=", width)
                    print("height=", height)
                    raw_frame = np.ndarray(shape=decoded_frame_size, dtype=np.uint8)
                    print(f"raw_frame.shape={raw_frame.shape}")
                    seq_triggered = True

                luma_base_addr = decoded_frame.GetPtrToPlane(0)
                if use_device_memory:
                    cuda.memcpy_dtoh(raw_frame, luma_base_addr)
                    bits = bytearray(raw_frame)
                    # print(type(bits))
                    # np_arr = np.array(bits)
                    np_arr = np.frombuffer(bits, dtype=np.uint8)

                    bgr_frame = cv2.cvtColor(np_arr.reshape((height * 3 // 2, width)), cv2.COLOR_YUV2BGR_NV12)

                else:
                    new_array = cast_address_to_1d_bytearray(base_address=luma_base_addr,
                                                             size=decoded_frame.framesize())

                    bgr_frame = cv2.cvtColor(new_array.reshape((height * 3 // 2, width)), cv2.COLOR_YUV2BGR_NV12)

                yield bgr_frame

                elapsed_time = time.time() - start_per
                # print(f"NV解码一帧时间: {elapsed_time}s")
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"PyNvVideoCodec average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")


```

# 3. [VALI](https://github.com/RomanArzumanyan/VALI)

## 3. 1 cuda 

```python
def get_gpu_info() -> dict:
    info = ''
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if device.type == "cuda":
        gpu_id_dict = {}
        for id in range(torch.cuda.device_count()):
            p = torch.cuda.get_device_properties(id)
            info += f'CUDA:{id} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n'
            gpu_id_dict[id] = p.name
        print(info[:-1])
        return gpu_id_dict
    else:
        info = "No GPU found"
        print(info)
        return {}


def read_frames3(video):
    url = video
    try:
        import python_vali as vali
        import pycuda
        import pycuda.autoinit
    except:
        print("Pycuda is required to run this sample")
    # download and display luma plane from nv12 decoded video frame
    # GPU-accelerated decoder
    gpu_id = 0
    gpu_info = get_gpu_info()
    print(f"GPU {gpu_info.get(gpu_id)} in Used By VALI Now")

    pyDec = vali.PyDecoder(
        url,
        {},
        gpu_id=gpu_id)

    # Example assumes pixel format is NV12
    assert (pyDec.Format == vali.PixelFormat.NV12)

    # Raw Surface, NV12 format
    surf_src = vali.Surface.Make(
        format=pyDec.Format,
        width=pyDec.Width,
        height=pyDec.Height,
        gpu_id=0)

    # Numpy buffer for collecting Y part of NV12 surface
    # y_buffer = np.ndarray(dtype=np.uint8, shape=pyDec.Width * pyDec.Height)
    y_buffer = np.zeros((pyDec.Height, pyDec.Width), dtype=np.uint8)
    uv_buffer = np.zeros((pyDec.Height // 2, pyDec.Width), dtype=np.uint8)

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        while True:
            start_per = time.perf_counter()
            num_decoded_frames += 1
            success, details = pyDec.DecodeSingleSurface(surf_src)
            if success:
                # NV12 是一种紧凑的像素格式，包含以下两部分：
                # 亮度平面 (Y)： 位于 NV12 的前 2/3 部分。
                # 色度平面 (UV)： 位于剩余的 1/3 部分，以交替的 UV 排布存储。

                # 下载亮度平面 (Y) 数据
                device_to_host_y = cuda.Memcpy2D()
                device_to_host_y.set_src_device(surf_src.Planes[0].GpuMem)
                device_to_host_y.set_dst_host(y_buffer)
                device_to_host_y.width_in_bytes = surf_src.Planes[0].Width
                device_to_host_y.src_pitch = surf_src.Planes[0].Pitch
                device_to_host_y.dst_pitch = surf_src.Planes[0].Width
                device_to_host_y.src_height = surf_src.Planes[0].Height * 2 // 3
                device_to_host_y.height = surf_src.Planes[0].Height * 2 // 3

                # 调用时显式传递 aligned 参数
                device_to_host_y(aligned=True)

                # 下载色度平面 (UV) 数据
                device_to_host_uv = cuda.Memcpy2D()
                device_to_host_uv.set_src_device(
                    surf_src.Planes[0].GpuMem + surf_src.Planes[0].Height * 2 // 3 * surf_src.Planes[0].Pitch
                )
                device_to_host_uv.set_dst_host(uv_buffer)
                device_to_host_uv.width_in_bytes = surf_src.Planes[0].Width
                device_to_host_uv.src_pitch = surf_src.Planes[0].Pitch
                device_to_host_uv.dst_pitch = surf_src.Planes[0].Width
                device_to_host_uv.src_height = surf_src.Planes[0].Height // 3
                device_to_host_uv.height = surf_src.Planes[0].Height // 3

                # 调用时显式传递 aligned 参数
                device_to_host_uv(aligned=True)

                # 组装 NV12 数据
                nv12_buffer = np.vstack((y_buffer, uv_buffer))

                # 将 NV12 转换为 BGR
                bgr_frame = cv2.cvtColor(nv12_buffer, cv2.COLOR_YUV2BGR_NV12)

                yield bgr_frame
                elapsed_time = time.perf_counter() - start_per
                # print(f"VALI解码一帧时间: {elapsed_time}s")

            else:
                break
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"VALI average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")


```

## 3.2 方法2

```python
def read_frames4(video):
    class StopExecution(Exception):
        def _render_traceback_(self):
            return []

    # Starting from Python 3.8 DLL search policy has changed.
    # We need to add path to CUDA DLLs explicitly.

    if os.name == "nt":
        # Add CUDA_PATH env variable
        cuda_path = os.environ["CUDA_PATH"]
        if cuda_path:
            os.add_dll_directory(os.path.join(cuda_path, "bin"))
        else:
            raise StopExecution
    try:
        import python_vali as vali
    except:
        print("vali need")

    url = video
    gpu_id = 0
    gpu_info = get_gpu_info()
    print(f"GPU {gpu_info.get(gpu_id)} in Used By VALI Now")

    # GPU-accelerated decoder
    pyDec = vali.PyDecoder(
        url,
        {},
        gpu_id=0)

    # GPU-accelerated converter
    pyCvt = vali.PySurfaceConverter(
        pyDec.Format,
        vali.PixelFormat.RGB,
        gpu_id=0)

    # GPU-accelerated Surface downloader
    pyDwn = vali.PySurfaceDownloader(gpu_id=0)

    # Raw decoded Surface
    surf_src = vali.Surface.Make(
        format=pyDec.Format,
        width=pyDec.Width,
        height=pyDec.Height,
        gpu_id=0)

    # Raw Surface, converted to RGB
    surf_dst = vali.Surface.Make(
        format=vali.PixelFormat.RGB,
        width=pyDec.Width,
        height=pyDec.Height,
        gpu_id=0)

    # Numpy array which contains decoded RGB Surface
    frame = np.ndarray(
        dtype=np.uint8,
        shape=surf_dst.HostSize)

    # Packet data
    pkt_data = vali.PacketData()

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        while True:
            start_per = time.perf_counter()
            num_decoded_frames += 1
            # Decode single Surface
            success, details = pyDec.DecodeSingleSurface(surf_src, pkt_data)

            if not success:
                print(f"Decode single Surface not success: {details}")
                break

            # Convert tot RGB
            success, details = pyCvt.Run(surf_src, surf_dst)
            if not success:
                print(f"Convert tot RGB not success: {details}")
                break

            # Copy pixels to numpy ndarray
            success, details = pyDwn.Run(surf_dst, frame)
            if not success:
                print(f"Copy pixels to numpy ndarray not success: {details}")
                break

            # Reshape to proper dimensions.
            # Some video formats like NV12 require to reshape to 'raw' dimensions.
            # Others like RGB24 require to reshape to 'final' dimensions. Hence this
            # feature isn't yet supported by VALI out of the box. Have to do that by
            # hand. Sic !
            res_frame = np.reshape(
                frame,
                (pyDec.Height, pyDec.Width, 3))
            bgr_frame = cv2.cvtColor(res_frame, cv2.COLOR_RGB2BGR)
            # cv2.imwrite("xx.jpg", bgr_frame)
            # break

            # Output packet data
            # print(pkt_data)

            yield bgr_frame
            elapsed_time = time.perf_counter() - start_per
            # print(f"VALI 2 解码一帧时间: {elapsed_time}s")
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"VALI 2 average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")

```
# 4. [ffio](https://github.com/dongrixinyu/ffio)

```python
def read_frames5(video):
    try:
        import ffio
    except:
        print("ffio need")

    """
    Infinite trying to open ffio, until ffio_state returns success.
    """
    while True:
        params = ffio.CCodecParams()
        decoder = ffio.FFIO(
            video, mode=ffio.FFIOMode.DECODE, hw_enabled=False,
            pix_fmt_hw_enabled=True, codec_params=params)

        if decoder:
            print('stream width: ', decoder.width)
            print('stream height: ', decoder.height)
            break

    start = time.perf_counter()
    num_decoded_frames = 0
    try:
        while True:
            start_per = time.perf_counter()
            frame = decoder.decode_one_frame()
            if not frame:
                break  # 当无法获取帧时，退出循环

            num_decoded_frames += 1
            image = frame.as_image()

            # Convert frame to numpy array and BGR format for OpenCV
            bgr_frame = cv2.cvtColor(np.asarray(image), cv2.COLOR_RGB2BGR)
            yield bgr_frame  # 产生帧对象

            # print(f"frame {num_decoded_frames}: {time.perf_counter() - start_per} sec.")

    # 这个finally块只有在生成器正常结束时才会执行
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"FFIO average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        decoder.release_memory()  # 释放解码器资源
```
# 5. [PyAV](https://github.com/PyAV-Org/PyAV)

```python
def read_frames6(video):
    container = av.open(video)
    container.streams.video[0].thread_type = "AUTO"
    width = container.streams.video[0].width
    height = container.streams.video[0].height
    print("width=", width)
    print("height=", height)

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        for frame in container.decode(video=0):
            # 记录开始时间
            start_per = time.perf_counter()
            num_decoded_frames += 1

            bgr_frame = frame.to_ndarray(format="bgr24")
            # 输出帧
            yield bgr_frame
            # print(f'PyAV解码一帧时间：{time.perf_counter() - start_per}')

    finally:
        final_elapsed = time.perf_counter() - start
        print(f"pyAV average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        container.close()
```

# 6. [deffcode](https://github.com/abhiTronix/deffcode)

```python
def read_frames7(video):
    try:
        # import the necessary packages
        from deffcode import FFdecoder
    except Exception:
        print("required deffcode")

    # initialize and formulate the decoder
    decoder = FFdecoder(video, frame_format="bgr24", verbose=False).formulate()

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        # grab RGB24(default) frame from decoder
        for frame in decoder.generateFrame():
            # 记录开始时间
            start_per = time.perf_counter()
            num_decoded_frames += 1

            # check if frame is None
            if frame is None:
                break

            # bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            # cv2.imwrite("xx.jpg", frame)
            # break
            yield frame

            # print(f'deffcode解码一帧时间：{(time.perf_counter() - start_per) * 1000}ms')

    finally:
        final_elapsed = time.perf_counter() - start
        print(f"deffcode average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        # terminate the decoder
        decoder.terminate()
```
# decode.py

```python
try:
    import time
    from functools import wraps
    import cv2
    import numpy as np
    import pycuda.driver as cuda
    import PyNvVideoCodec as nvc
    import av
    import ctypes as C
    import torch
    import os
except ImportError as e:
    pass


def generator_decorator(lib_name):
    def actual_decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start = time.perf_counter()
            gen = func(*args, **kwargs)
            num_frames = 0
            try:
                for item in gen:
                    num_frames += 1
                    yield item
            finally:
                elapsed = time.perf_counter() - start
                if num_frames > 0:
                    avg_time = elapsed / num_frames * 1000
                    print(f"GD {lib_name} average per frame cost time: {avg_time:.2f}ms")

        return wrapper

    return actual_decorator


@generator_decorator(lib_name="OpenCV")
def read_frames(video_name):
    cap = cv2.VideoCapture(video_name)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print("width=", width)
    print("height=", height)
    # warmup
    for i in range(10):
        cap.read()

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        while True:
            start_per = time.perf_counter()
            num_decoded_frames += 1

            ret, frame = cap.read()
            if ret:
                yield frame
                # print(f'CV解码一帧时间：{time.perf_counter() - start_per}')
            else:
                break

    finally:
        final_elapsed = time.perf_counter() - start
        print(f"Opencv average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        cap.release()


def cast_address_to_1d_bytearray(base_address, size):
    return np.ctypeslib.as_array(C.cast(base_address, C.POINTER(C.c_uint8)),
                                 shape=(size,))


@generator_decorator(lib_name="PyNvVideoCodec")
def read_frames2(video_name, gpu_id=0, use_device_memory=False):
    nv_dmx = nvc.CreateDemuxer(filename=video_name)
    nv_dec = nvc.CreateDecoder(gpuid=gpu_id,
                               codec=nv_dmx.GetNvCodecId(),
                               cudacontext=0,
                               cudastream=0,
                               usedevicememory=use_device_memory)

    raw_frame = None

    seq_triggered = False
    # printing out FPS and pixel format of the stream for convenience
    print("FPS = ", nv_dmx.FrameRate())

    width = 0
    height = 0

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        # demuxer can be iterated, fetch the packet from demuxer
        for packet in nv_dmx:
            # Decode returns a list of packets, range of this list is from [0, size of (decode picture buffer)]
            # size of (decode picture buffer) depends on GPU, fur Turing series its 8
            for decoded_frame in nv_dec.Decode(packet):
                # 'decoded_frame' contains list of views implementing cuda array interface
                # for nv12, it would contain 2 views for each plane and two planes would be contiguous

                start_per = time.time()
                num_decoded_frames += 1

                if not seq_triggered:
                    decoded_frame_size = nv_dec.GetFrameSize()
                    print(f"decoded_frame_size={decoded_frame_size}")
                    width = nv_dec.GetWidth()
                    height = nv_dec.GetHeight()
                    print("width=", width)
                    print("height=", height)
                    raw_frame = np.ndarray(shape=decoded_frame_size, dtype=np.uint8)
                    print(f"raw_frame.shape={raw_frame.shape}")
                    seq_triggered = True

                luma_base_addr = decoded_frame.GetPtrToPlane(0)
                if use_device_memory:
                    cuda.memcpy_dtoh(raw_frame, luma_base_addr)
                    bits = bytearray(raw_frame)
                    # print(type(bits))
                    # np_arr = np.array(bits)
                    np_arr = np.frombuffer(bits, dtype=np.uint8)

                    bgr_frame = cv2.cvtColor(np_arr.reshape((height * 3 // 2, width)), cv2.COLOR_YUV2BGR_NV12)

                else:
                    new_array = cast_address_to_1d_bytearray(base_address=luma_base_addr,
                                                             size=decoded_frame.framesize())

                    bgr_frame = cv2.cvtColor(new_array.reshape((height * 3 // 2, width)), cv2.COLOR_YUV2BGR_NV12)

                yield bgr_frame

                elapsed_time = time.time() - start_per
                # print(f"NV解码一帧时间: {elapsed_time}s")
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"PyNvVideoCodec average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")


def get_gpu_info() -> dict:
    info = ''
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if device.type == "cuda":
        gpu_id_dict = {}
        for id in range(torch.cuda.device_count()):
            p = torch.cuda.get_device_properties(id)
            info += f'CUDA:{id} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\n'
            gpu_id_dict[id] = p.name
        print(info[:-1])
        return gpu_id_dict
    else:
        info = "No GPU found"
        print(info)
        return {}


@generator_decorator(lib_name="VALI Cuda")
def read_frames3(video):
    url = video
    try:
        import python_vali as vali
        import pycuda
        import pycuda.autoinit
    except:
        print("Pycuda is required to run this sample")
    # download and display luma plane from nv12 decoded video frame
    # GPU-accelerated decoder
    gpu_id = 0
    gpu_info = get_gpu_info()
    print(f"GPU {gpu_info.get(gpu_id)} in Used By VALI Now")

    pyDec = vali.PyDecoder(
        url,
        {},
        gpu_id=gpu_id)

    # Example assumes pixel format is NV12
    assert (pyDec.Format == vali.PixelFormat.NV12)

    # Raw Surface, NV12 format
    surf_src = vali.Surface.Make(
        format=pyDec.Format,
        width=pyDec.Width,
        height=pyDec.Height,
        gpu_id=0)

    # Numpy buffer for collecting Y part of NV12 surface
    # y_buffer = np.ndarray(dtype=np.uint8, shape=pyDec.Width * pyDec.Height)
    y_buffer = np.zeros((pyDec.Height, pyDec.Width), dtype=np.uint8)
    uv_buffer = np.zeros((pyDec.Height // 2, pyDec.Width), dtype=np.uint8)

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        while True:
            start_per = time.perf_counter()
            num_decoded_frames += 1
            success, details = pyDec.DecodeSingleSurface(surf_src)
            if success:
                # NV12 是一种紧凑的像素格式，包含以下两部分：
                # 亮度平面 (Y)： 位于 NV12 的前 2/3 部分。
                # 色度平面 (UV)： 位于剩余的 1/3 部分，以交替的 UV 排布存储。

                # 下载亮度平面 (Y) 数据
                device_to_host_y = cuda.Memcpy2D()
                device_to_host_y.set_src_device(surf_src.Planes[0].GpuMem)
                device_to_host_y.set_dst_host(y_buffer)
                device_to_host_y.width_in_bytes = surf_src.Planes[0].Width
                device_to_host_y.src_pitch = surf_src.Planes[0].Pitch
                device_to_host_y.dst_pitch = surf_src.Planes[0].Width
                device_to_host_y.src_height = surf_src.Planes[0].Height * 2 // 3
                device_to_host_y.height = surf_src.Planes[0].Height * 2 // 3

                # 调用时显式传递 aligned 参数
                device_to_host_y(aligned=True)

                # 下载色度平面 (UV) 数据
                device_to_host_uv = cuda.Memcpy2D()
                device_to_host_uv.set_src_device(
                    surf_src.Planes[0].GpuMem + surf_src.Planes[0].Height * 2 // 3 * surf_src.Planes[0].Pitch
                )
                device_to_host_uv.set_dst_host(uv_buffer)
                device_to_host_uv.width_in_bytes = surf_src.Planes[0].Width
                device_to_host_uv.src_pitch = surf_src.Planes[0].Pitch
                device_to_host_uv.dst_pitch = surf_src.Planes[0].Width
                device_to_host_uv.src_height = surf_src.Planes[0].Height // 3
                device_to_host_uv.height = surf_src.Planes[0].Height // 3

                # 调用时显式传递 aligned 参数
                device_to_host_uv(aligned=True)

                # 组装 NV12 数据
                nv12_buffer = np.vstack((y_buffer, uv_buffer))

                # 将 NV12 转换为 BGR
                bgr_frame = cv2.cvtColor(nv12_buffer, cv2.COLOR_YUV2BGR_NV12)

                yield bgr_frame
                elapsed_time = time.perf_counter() - start_per
                # print(f"VALI解码一帧时间: {elapsed_time}s")

            else:
                break
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"VALI average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")


@generator_decorator(lib_name="VALI 2")
def read_frames4(video):
    class StopExecution(Exception):
        def _render_traceback_(self):
            return []

    # Starting from Python 3.8 DLL search policy has changed.
    # We need to add path to CUDA DLLs explicitly.

    if os.name == "nt":
        # Add CUDA_PATH env variable
        cuda_path = os.environ["CUDA_PATH"]
        if cuda_path:
            os.add_dll_directory(os.path.join(cuda_path, "bin"))
        else:
            raise StopExecution
    try:
        import python_vali as vali
    except:
        print("vali need")

    url = video
    gpu_id = 0
    gpu_info = get_gpu_info()
    print(f"GPU {gpu_info.get(gpu_id)} in Used By VALI Now")

    # GPU-accelerated decoder
    pyDec = vali.PyDecoder(
        url,
        {},
        gpu_id=0)

    # GPU-accelerated converter
    pyCvt = vali.PySurfaceConverter(
        pyDec.Format,
        vali.PixelFormat.RGB,
        gpu_id=0)

    # GPU-accelerated Surface downloader
    pyDwn = vali.PySurfaceDownloader(gpu_id=0)

    # Raw decoded Surface
    surf_src = vali.Surface.Make(
        format=pyDec.Format,
        width=pyDec.Width,
        height=pyDec.Height,
        gpu_id=0)

    # Raw Surface, converted to RGB
    surf_dst = vali.Surface.Make(
        format=vali.PixelFormat.RGB,
        width=pyDec.Width,
        height=pyDec.Height,
        gpu_id=0)

    # Numpy array which contains decoded RGB Surface
    frame = np.ndarray(
        dtype=np.uint8,
        shape=surf_dst.HostSize)

    # Packet data
    pkt_data = vali.PacketData()

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        while True:
            start_per = time.perf_counter()
            num_decoded_frames += 1
            # Decode single Surface
            success, details = pyDec.DecodeSingleSurface(surf_src, pkt_data)

            if not success:
                print(f"Decode single Surface not success: {details}")
                break

            # Convert tot RGB
            success, details = pyCvt.Run(surf_src, surf_dst)
            if not success:
                print(f"Convert tot RGB not success: {details}")
                break

            # Copy pixels to numpy ndarray
            success, details = pyDwn.Run(surf_dst, frame)
            if not success:
                print(f"Copy pixels to numpy ndarray not success: {details}")
                break

            # Reshape to proper dimensions.
            # Some video formats like NV12 require to reshape to 'raw' dimensions.
            # Others like RGB24 require to reshape to 'final' dimensions. Hence this
            # feature isn't yet supported by VALI out of the box. Have to do that by
            # hand. Sic !
            res_frame = np.reshape(
                frame,
                (pyDec.Height, pyDec.Width, 3))
            bgr_frame = cv2.cvtColor(res_frame, cv2.COLOR_RGB2BGR)
            # cv2.imwrite("xx.jpg", bgr_frame)
            # break

            # Output packet data
            # print(pkt_data)

            yield bgr_frame
            elapsed_time = time.perf_counter() - start_per
            # print(f"VALI 2 解码一帧时间: {elapsed_time}s")
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"VALI 2 average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")


@generator_decorator(lib_name="ffio")
def read_frames5(video):
    try:
        import ffio
    except:
        print("ffio need")

    """
    Infinite trying to open ffio, until ffio_state returns success.
    """
    while True:
        params = ffio.CCodecParams()
        decoder = ffio.FFIO(
            video, mode=ffio.FFIOMode.DECODE, hw_enabled=False,
            pix_fmt_hw_enabled=True, codec_params=params)

        if decoder:
            print('stream width: ', decoder.width)
            print('stream height: ', decoder.height)
            break

    start = time.perf_counter()
    num_decoded_frames = 0
    try:
        while True:
            start_per = time.perf_counter()
            frame = decoder.decode_one_frame()
            if not frame:
                break  # 当无法获取帧时，退出循环

            num_decoded_frames += 1
            image = frame.as_image()

            # Convert frame to numpy array and BGR format for OpenCV
            bgr_frame = cv2.cvtColor(np.asarray(image), cv2.COLOR_RGB2BGR)
            yield bgr_frame  # 产生帧对象

            # print(f"frame {num_decoded_frames}: {time.perf_counter() - start_per} sec.")

    # 这个finally块只有在生成器正常结束时才会执行
    finally:
        final_elapsed = time.perf_counter() - start
        print(f"FFIO average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        decoder.release_memory()  # 释放解码器资源


@generator_decorator(lib_name="PyAV")
def read_frames6(video):
    container = av.open(video)
    container.streams.video[0].thread_type = "AUTO"
    width = container.streams.video[0].width
    height = container.streams.video[0].height
    print("width=", width)
    print("height=", height)

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        for frame in container.decode(video=0):
            # 记录开始时间
            start_per = time.perf_counter()
            num_decoded_frames += 1

            bgr_frame = frame.to_ndarray(format="bgr24")
            # 输出帧
            yield bgr_frame
            # print(f'PyAV解码一帧时间：{time.perf_counter() - start_per}')

    finally:
        final_elapsed = time.perf_counter() - start
        print(f"pyAV average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        container.close()


@generator_decorator(lib_name="deffcode")
def read_frames7(video):
    try:
        # import the necessary packages
        from deffcode import FFdecoder
    except Exception:
        print("required deffcode")

    # initialize and formulate the decoder
    decoder = FFdecoder(video, frame_format="bgr24", verbose=False).formulate()

    start = time.perf_counter()
    num_decoded_frames = 0

    try:
        # grab RGB24(default) frame from decoder
        for frame in decoder.generateFrame():
            # 记录开始时间
            start_per = time.perf_counter()
            num_decoded_frames += 1

            # check if frame is None
            if frame is None:
                break

            # bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            # cv2.imwrite("xx.jpg", frame)
            # break
            yield frame

            # print(f'deffcode解码一帧时间：{(time.perf_counter() - start_per) * 1000}ms')

    finally:
        final_elapsed = time.perf_counter() - start
        print(f"deffcode average per frame cost time: {final_elapsed / num_decoded_frames * 1000}ms")
        # terminate the decoder
        decoder.terminate()
```

# test_decode.py

```python
from decode import *

def test_decoder(decode_func, vid, decode_name=None, stop_frame=1, framerate=30):
    if decode_name is not None:
        print("-" * 100)
        print(decode_name)
        print("-" * 100)

    for i, frame in enumerate(decode_func(vid)):
        # print(i)
        if i >= stop_frame * framerate:
            break

        # if vid.startswith("rtsp://") and i > stop_frame * framerate:
        #     break
        pass


def main():
    video_dir = "./video"
    video_list = {
        "1080p": f"{video_dir}/2c1080p.mp4",
        "2k": f"{video_dir}/2c2k.mp4",
        "4k": f"{video_dir}/2c4k.mp4",
        # "8k": f"{video_dir}/2c1080p.mp4",
    }

    decode_funcs = {
        "Opencv": read_frames,
        "NV": read_frames2,
        # "VALI 1": read_frames3,
        # "VALI 2": read_frames4,
        # "ffio": read_frames5,
        "PyAV": read_frames6,
        # "deffcode": read_frames7
    }

    for decode_n, decode_f in decode_funcs.items():
        for vid_n, vid in video_list.items():
            print(f"video resolution {vid_n}")
            test_decoder(decode_f, vid, decode_n, stop_frame=1, framerate=60)


if __name__ == '__main__':
    main()
```


# 测试结果

测试环境：Ubuntu 20.04.6 LTS  NVIDIA GeForce RTX 4090

```
1080p

Opencv average per frame cost time: 3.9121522544921934ms
FFIO average per frame cost time: 28.069625959999723ms


Opencv average per frame cost time: 3.720645801983185ms
PyNvVideoCodec average per frame cost time: 1.5427116006333845ms
VALI average per frame cost time: 2.084697657260895ms
VALI 2 average per frame cost time: 1.6580219284674702ms
pyAV average per frame cost time: 4.257339376048921ms
deffcode average per frame cost time: 4.2108922629049985ms
```


